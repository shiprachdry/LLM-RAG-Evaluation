{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9df8717b",
   "metadata": {},
   "source": [
    "## RAG Evalutation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4f2d7b",
   "metadata": {},
   "source": [
    "### Evaluation Strategy: \n",
    "\n",
    "For every query, our retreiver will retrieve top 3,5,7 documents. From our query-corpus dataset, we will match if the documents retreived match/are in the groud truth document mapped to a query.\n",
    "\n",
    "### Retreiver Strategy:\n",
    "1. We will use embedding based retreival techniques - text-embedding-ada-002 from GenAI hub as well as keyword based retreivels like BM25. \n",
    "\n",
    "2. We will use open-source BGE re-ranking model to augment the retreival performance\n",
    "\n",
    "3. We will try Fusion ( index & query re-writing) to see if there is an increase in the performance\n",
    "\n",
    "4. We are not evaluating the cost/latency for this POC which could be influcened by CPUs/ data size. \n",
    "\n",
    "5. Vector Store: I'm using FAISS vector store which is one of the most efficient & fastest technique and uses ANN for indexing the document. \n",
    "\n",
    "6. Framework : using LlamaIndex framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61f531b",
   "metadata": {},
   "source": [
    "#### Defining llm & embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e8d5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_commons.langchain.proxy import ChatOpenAI\n",
    "from llm_commons.langchain.proxy import OpenAIEmbeddings\n",
    "from ipywidgets import widgets\n",
    "\n",
    "llm_model_name = widgets.Dropdown(\n",
    "    options=[\n",
    "        \"gpt-35-turbo\",\n",
    "        \"gpt-35-turbo-16k\",\n",
    "        \"gpt-4\",\n",
    "        \"gpt-4-32k\",\n",
    "        \"gpt-4-turbo\",\n",
    "        \"gemini-1.0-pro\",\n",
    "        \"gpt-4-vision\"\n",
    "        # \"tiiuae--falcon-40b-instruct\"\n",
    "    ],\n",
    "    value=\"gpt-35-turbo-16k\",\n",
    "    description=\"LLM Model Name\",\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(proxy_model_name=llm_model_name.value)\n",
    "embeddings = OpenAIEmbeddings(proxy_model_name='text-embedding-ada-002')\n",
    "\n",
    "from llama_index.embeddings.langchain import LangchainEmbedding\n",
    "from llama_index.llms.langchain import LangChainLLM\n",
    "\n",
    "llama_llm = LangChainLLM(llm)\n",
    "llama_emb= LangchainEmbedding(embeddings)\n",
    "\n",
    "from llama_index.core import Settings\n",
    "Settings.embed_model = embeddings\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef017910",
   "metadata": {},
   "source": [
    "#### Loading open source SciFact Dataset from BIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab7a50c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\I068117\\Anaconda3\\envs\\myenv10\\lib\\site-packages\\beir\\util.py:2: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from beir import util\n",
    "from beir.datasets.data_loader import GenericDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab11f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Download scifact.zip dataset and unzip the dataset\n",
    "import logging\n",
    "import pathlib, os\n",
    "dataset = \"scifact\"\n",
    "url = \"https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/{}.zip\".format(dataset)\n",
    "out_dir = os.path.join(pathlib.Path(\"C:/Users/I068117/UT_Machine Learning/Custom-AI-Chatbot-RAG\").parent.absolute(), \"datasets\")\n",
    "data_path = util.download_and_unzip(url, out_dir)\n",
    "\n",
    "#### Provide the data_path where scifact has been downloaded and unzipped\n",
    "corpus, queries, qrels = GenericDataLoader(data_folder=data_path).load(split=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17cb1f2",
   "metadata": {},
   "source": [
    "#### Each corpus id is a single document, which we will use for our evaluation. There are 5183 documents in the corpus with a mean chunk size of 1400 words\n",
    "\n",
    "We are not doing any chunking as each document is chunked as per the corpus id\n",
    "\n",
    "Later, we will explore combining the whole document into one document and then chunking it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93f0574d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4983</td>\n",
       "      <td>Microstructural development of human newborn c...</td>\n",
       "      <td>Alterations of the architecture of cerebral wh...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5836</td>\n",
       "      <td>Induction of myelodysplasia by myeloid-derived...</td>\n",
       "      <td>Myelodysplastic syndromes (MDS) are age-depend...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7912</td>\n",
       "      <td>BC1 RNA, the transcript from a master gene for...</td>\n",
       "      <td>ID elements are short interspersed elements (S...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18670</td>\n",
       "      <td>The DNA Methylome of Human Peripheral Blood Mo...</td>\n",
       "      <td>DNA methylation plays an important role in bio...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19238</td>\n",
       "      <td>The human myelin basic protein gene is include...</td>\n",
       "      <td>Two human Golli (for gene expressed in the oli...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     _id                                              title  \\\n",
       "0   4983  Microstructural development of human newborn c...   \n",
       "1   5836  Induction of myelodysplasia by myeloid-derived...   \n",
       "2   7912  BC1 RNA, the transcript from a master gene for...   \n",
       "3  18670  The DNA Methylome of Human Peripheral Blood Mo...   \n",
       "4  19238  The human myelin basic protein gene is include...   \n",
       "\n",
       "                                                text metadata  \n",
       "0  Alterations of the architecture of cerebral wh...       {}  \n",
       "1  Myelodysplastic syndromes (MDS) are age-depend...       {}  \n",
       "2  ID elements are short interspersed elements (S...       {}  \n",
       "3  DNA methylation plays an important role in bio...       {}  \n",
       "4  Two human Golli (for gene expressed in the oli...       {}  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the JSON Lines file\n",
    "df_corpus = pd.read_json('C:/Users/I068117/UT_Machine Learning/datasets/scifact/corpus.jsonl', lines=True)\n",
    "df_corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cb9026",
   "metadata": {},
   "source": [
    "#### Current chunk size for the documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "df77903f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1401.0839282268955\n"
     ]
    }
   ],
   "source": [
    "text_length= df_corpus['text'].apply(lambda x : len(x)).mean()\n",
    "print(text_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8962c3",
   "metadata": {},
   "source": [
    "#### Queries df - There are 1109 queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65fad8f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>text</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0-dimensional biomaterials lack inductive prop...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1 in 5 million in UK have abnormal PrP positiv...</td>\n",
       "      <td>{'13734012': [{'sentences': [4], 'label': 'CON...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1-1% of colorectal cancer patients are diagnos...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>10% of sudden infant death syndrome (SIDS) dea...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>32% of liver transplantation programs required...</td>\n",
       "      <td>{'44265107': [{'sentences': [15], 'label': 'SU...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _id                                               text  \\\n",
       "0    0  0-dimensional biomaterials lack inductive prop...   \n",
       "1    2  1 in 5 million in UK have abnormal PrP positiv...   \n",
       "2    4  1-1% of colorectal cancer patients are diagnos...   \n",
       "3    6  10% of sudden infant death syndrome (SIDS) dea...   \n",
       "4    9  32% of liver transplantation programs required...   \n",
       "\n",
       "                                            metadata  \n",
       "0                                                 {}  \n",
       "1  {'13734012': [{'sentences': [4], 'label': 'CON...  \n",
       "2                                                 {}  \n",
       "3                                                 {}  \n",
       "4  {'44265107': [{'sentences': [15], 'label': 'SU...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the JSON Lines file\n",
    "df_queries = pd.read_json('C:/Users/I068117/UT_Machine Learning/datasets/scifact/queries.jsonl', lines=True)\n",
    "df_queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "659c506d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1109"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee2781f",
   "metadata": {},
   "source": [
    "#### Each Query is mapped to a corpus-id document as the ground truth. There are 919 queries mapped to a corpus id in the train Q&A set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04680ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query-id</th>\n",
       "      <th>corpus-id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>31715818</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>13734012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>22942787</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>2613775</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>44265107</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query-id  corpus-id  score\n",
       "0         0   31715818      1\n",
       "1         2   13734012      1\n",
       "2         4   22942787      1\n",
       "3         6    2613775      1\n",
       "4         9   44265107      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "df=pd.read_csv('C:/Users/I068117/UT_Machine Learning/datasets/scifact/qrels/train.tsv',sep=\"\\t\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a28f001",
   "metadata": {},
   "source": [
    "##### Getting unique query id with all relevant documents as one query could have 1 or more relevant documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fabeefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_key = df.groupby('query-id')['corpus-id'].agg(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a120c86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------optional to load embeddings & storing locally---------------\n",
    "new=[]\n",
    "for d in data:\n",
    "    new.append(embeddings.embed_query(d.page_content))\n",
    "df_corpus['emb']=new\n",
    "\n",
    "#df_corpus.to_excel('scifact_emd.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a106e15",
   "metadata": {},
   "source": [
    "#### LLama_Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ed4de5f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "data_Json = []\n",
    "\n",
    "with open(\"corpus.jsonl\", \"r\") as file:\n",
    "    for line in file:\n",
    "        data_Json.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "af01ff03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the list of JSON objects to a JSON file\n",
    "with open('corpus.json', 'w') as json_file:\n",
    "    json.dump(data_Json, json_file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cedc7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    load_index_from_storage,\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    ")\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecebc2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "d = 1536\n",
    "faiss_index = faiss.IndexFlatL2(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9c958baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting document from Langchain to Llama_index document\n",
    "from llama_index.core import Document\n",
    "docs_llama=[]\n",
    "for doc in docs_langchain:\n",
    "    docs_llama.append(Document.from_langchain_format(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "cca0a3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = FaissVectorStore(faiss_index=faiss_index)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    docs_llama, storage_context=storage_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "87af853d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing index on the disk\n",
    "index.storage_context.persist(persist_dir=\"C:/Users/I068117/UT_Machine Learning/Custom-AI-Chatbot-RAG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfebf2bd",
   "metadata": {},
   "source": [
    "### VectorStore Retreiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a338eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "\n",
    "# load index from disk\n",
    "vector_store = FaissVectorStore.from_persist_dir(\"C:/Users/I068117/UT_Machine Learning/Custom-AI-Chatbot-RAG\")\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    vector_store=vector_store, persist_dir=\"C:/Users/I068117/UT_Machine Learning/Custom-AI-Chatbot-RAG\"\n",
    ")\n",
    "\n",
    "#loading the index from the local directory to avoid loading the embeddings\n",
    "index = load_index_from_storage(storage_context=storage_context)\n",
    "#context = vector_retriever.retrieve(\"A deficiency of vitamin B12 decreases blood levels of homocysteine\")\n",
    "#print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e2ae1daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_retriever_corpus_index(x,topk):\n",
    "    vector_retriever = index.as_retriever(similarity_top_k=topk)\n",
    "    context = vector_retriever.retrieve(x)\n",
    "    ci=[]\n",
    "    for c in context:\n",
    "        ci.append(c.node.metadata['idx'])\n",
    "    return ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "89e26b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate recall\n",
    "def calculate_recall(row,k):\n",
    "    matches = len(set(list(map(str,row['corpus-id']))) & set(list(row[f'top{k}'])))\n",
    "    return matches / len(row['corpus-id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "19be4c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate recall\n",
    "def calculate_precision(row,k):\n",
    "    matches = len(set(list(map(str,row['corpus-id']))) & set(list(row[f'top{k}'])))\n",
    "    return matches / len(row[f'top{k}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "18456512",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def calculate_reciprocal_rank(row, k):\n",
    "    mrr = []\n",
    "    for idx in row['corpus-id']:\n",
    "        if str(idx) not in row[f'top{k}']:\n",
    "            mrr.append(0)\n",
    "        else:\n",
    "            mrr.append(1 / (row[f'top{k}'].index(str(idx)) + 1))\n",
    "    return sum(mrr) / len(mrr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e59954e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval=pd.DataFrame(columns=['_id','query'])\n",
    "df_eval[['_id','query']]= df_queries.iloc[:100,:2]\n",
    "df_eval_merge= df_eval.merge(df_key,left_on='_id',right_on='query-id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8b0ed7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_merge['top3']=df_eval_merge['query'].apply(lambda x: vector_retriever_corpus_index(x,topk=3))\n",
    "df_eval_merge['top5']=df_eval_merge['query'].apply(lambda x:vector_retriever_corpus_index(x,topk=5))\n",
    "df_eval_merge['top7']=df_eval_merge['query'].apply(lambda x:vector_retriever_corpus_index(x,topk=7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1852a2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_merge['recall@3'] = df_eval_merge.apply(lambda x:calculate_recall(x,k=3), axis=1)\n",
    "df_eval_merge['recall@5'] = df_eval_merge.apply(lambda x:calculate_recall(x,k=5), axis=1)\n",
    "df_eval_merge['recall@7'] = df_eval_merge.apply(lambda x:calculate_recall(x,k=7), axis=1)\n",
    "\n",
    "df_eval_merge['MRR@3'] = df_eval_merge.apply(lambda x:calculate_reciprocal_rank(x,k=3), axis=1)\n",
    "df_eval_merge['MRR@5'] = df_eval_merge.apply(lambda x:calculate_reciprocal_rank(x,k=5), axis=1)\n",
    "df_eval_merge['MRR@7'] = df_eval_merge.apply(lambda x:calculate_reciprocal_rank(x,k=7), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "c78bd5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Retreival_Technique</th>\n",
       "      <th>Recall@3</th>\n",
       "      <th>Recall@5</th>\n",
       "      <th>Recall@7</th>\n",
       "      <th>MRR@3</th>\n",
       "      <th>MRR@5</th>\n",
       "      <th>MRR@7</th>\n",
       "      <th>HT@3</th>\n",
       "      <th>HT@5</th>\n",
       "      <th>HT@7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text-embedding-ada-002</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Retreival_Technique  Recall@3  Recall@5  Recall@7  MRR@3  MRR@5  MRR@7  \\\n",
       "0  text-embedding-ada-002      0.72      0.82      0.84   0.66   0.69   0.69   \n",
       "\n",
       "   HT@3  HT@5  HT@7  \n",
       "0  0.73  0.84  0.86  "
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = pd.DataFrame([{\n",
    "    'Retreival_Technique': 'text-embedding-ada-002',\n",
    "    'Recall@3': round(df_eval_merge['recall@3'].mean(), 2),\n",
    "    'Recall@5': round(df_eval_merge['recall@5'].mean(), 2),\n",
    "    'Recall@7': round(df_eval_merge['recall@7'].mean(), 2),\n",
    "    'MRR@3': round(df_eval_merge['MRR@3'].mean(), 2),\n",
    "    'MRR@5': round(df_eval_merge['MRR@5'].mean(), 2),\n",
    "    'MRR@7': round(df_eval_merge['MRR@7'].mean(), 2),\n",
    "    'HT@3': round(df_eval_merge[df_eval_merge['recall@3'] != 0].shape[0] / len(df_eval_merge), 2),\n",
    "    'HT@5': round(df_eval_merge[df_eval_merge['recall@5'] != 0].shape[0] / len(df_eval_merge), 2),\n",
    "    'HT@7': round(df_eval_merge[df_eval_merge['recall@7'] != 0].shape[0] / len(df_eval_merge), 2)\n",
    "}])\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7ae837",
   "metadata": {},
   "source": [
    "### Vectorstore retreiver with a re-ranker(top 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "3ae79a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_rerank_retriever = index.as_retriever(similarity_top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "86af419c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vector_rerank_eval=pd.DataFrame(columns=['_id','query'])\n",
    "df_vector_rerank_eval[['_id','query']]= df_queries.iloc[:100,:2]\n",
    "df_vector_rerank_eval_merge= df_vector_rerank_eval.merge(df_key,left_on='_id',right_on='query-id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "c6b4e0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vector_rerank_eval_merge['top5']=df_vector_rerank_eval_merge['query'].apply(lambda x:re_ranker(vector_rerank_retriever.retrieve(x),x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0866e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vector_rerank_eval_merge['recall@5'] = df_vector_rerank_eval_merge.apply(lambda x:calculate_recall(x,k=5), axis=1)\n",
    "df_vector_rerank_eval_merge['MRR@5'] = df_vector_rerank_eval_merge.apply(lambda x:calculate_reciprocal_rank(x,k=5), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "cc45fbab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Retreival_Technique</th>\n",
       "      <th>Recall@3</th>\n",
       "      <th>Recall@5</th>\n",
       "      <th>Recall@7</th>\n",
       "      <th>MRR@3</th>\n",
       "      <th>MRR@5</th>\n",
       "      <th>MRR@7</th>\n",
       "      <th>HT@3</th>\n",
       "      <th>HT@5</th>\n",
       "      <th>HT@7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text-embedding-ada-002</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>text-embedding-ada-002 + BGE Re_ranker_top5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.85</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Retreival_Technique  Recall@3  Recall@5  Recall@7  \\\n",
       "0                       text-embedding-ada-002      0.72      0.82      0.84   \n",
       "1  text-embedding-ada-002 + BGE Re_ranker_top5       NaN      0.82       NaN   \n",
       "\n",
       "   MRR@3  MRR@5  MRR@7  HT@3  HT@5  HT@7  \n",
       "0   0.66   0.69   0.69  0.73  0.84  0.86  \n",
       "1    NaN   0.67    NaN   NaN  0.85   NaN  "
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = {\n",
    "    'Retreival_Technique': 'text-embedding-ada-002 + BGE Re_ranker_top5',\n",
    "    'Recall@5': round(df_vector_rerank_eval_merge['recall@5'].mean() , 2),  # Adjust these as needed\n",
    "    'MRR@5': round(df_vector_rerank_eval_merge['MRR@5'].mean(), 2),\n",
    "    'HT@5': round(df_vector_rerank_eval_merge[df_vector_rerank_eval_merge['recall@5'] != 0].shape[0] / len(df_vector_rerank_eval_merge), 2),\n",
    "}\n",
    "\n",
    "eval_df.loc[len(eval_df)] = new_data\n",
    "\n",
    "eval_df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2861730",
   "metadata": {},
   "source": [
    "### BM25 retreiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6bb3ed14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can pass in the index, doctore, or list of nodes to create the retriever\n",
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "BM25_retriever = BM25Retriever.from_defaults(nodes=docs_llama, similarity_top_k=7)\n",
    "def BM25_retriever_corpus_index(x):\n",
    "    context = BM25_retriever.retrieve(x)\n",
    "    ci=[]\n",
    "    for c in context:\n",
    "        ci.append(c.node.metadata['idx'])\n",
    "    return ci\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f1faede5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BM_eval=pd.DataFrame(columns=['_id','query'])\n",
    "df_BM_eval[['_id','query']]= df_queries.iloc[:100,:2]\n",
    "df_BM_eval_merge= df_BM_eval.merge(df_key,left_on='_id',right_on='query-id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "46293509",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BM_eval_merge['top3']=df_BM_eval_merge['query'].apply(lambda x: BM25_retriever_corpus_index(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d970e550",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BM_eval_merge['top5']=df_BM_eval_merge['query'].apply(lambda x:BM25_retriever_corpus_index(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0a0ffa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BM_eval_merge['top7']=df_BM_eval_merge['query'].apply(lambda x:BM25_retriever_corpus_index(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4e0999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to each row\n",
    "df_BM_eval_merge['recall@3'] = df_BM_eval_merge.apply(lambda x:calculate_recall(x,k=3), axis=1)\n",
    "df_BM_eval_merge['recall@5'] = df_BM_eval_merge.apply(lambda x:calculate_recall(x,k=5), axis=1)\n",
    "df_BM_eval_merge['recall@7'] = df_BM_eval_merge.apply(lambda x:calculate_recall(x,k=7), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25728991",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BM_eval_merge['MRR@3'] = df_BM_eval_merge.apply(lambda x:calculate_reciprocal_rank(x,k=3), axis=1)\n",
    "df_BM_eval_merge['MRR@5'] = df_BM_eval_merge.apply(lambda x:calculate_reciprocal_rank(x,k=5), axis=1)\n",
    "df_BM_eval_merge['MRR@7'] = df_BM_eval_merge.apply(lambda x:calculate_reciprocal_rank(x,k=7), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "f84a069e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Retreival_Technique</th>\n",
       "      <th>Recall@3</th>\n",
       "      <th>Recall@5</th>\n",
       "      <th>Recall@7</th>\n",
       "      <th>MRR@3</th>\n",
       "      <th>MRR@5</th>\n",
       "      <th>MRR@7</th>\n",
       "      <th>HT@3</th>\n",
       "      <th>HT@5</th>\n",
       "      <th>HT@7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text-embedding-ada-002</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>text-embedding-ada-002 + BGE Re_ranker_top5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.85</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BM25 Retreiver</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Retreival_Technique  Recall@3  Recall@5  Recall@7  \\\n",
       "0                       text-embedding-ada-002      0.72      0.82      0.84   \n",
       "1  text-embedding-ada-002 + BGE Re_ranker_top5       NaN      0.82       NaN   \n",
       "2                               BM25 Retreiver      0.63      0.68      0.70   \n",
       "\n",
       "   MRR@3  MRR@5  MRR@7  HT@3  HT@5  HT@7  \n",
       "0   0.66   0.69   0.69  0.73  0.84  0.86  \n",
       "1    NaN   0.67    NaN   NaN  0.85   NaN  \n",
       "2   0.49   0.50   0.50  0.64  0.69  0.71  "
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = {\n",
    "    'Retreival_Technique': 'BM25 Retreiver',\n",
    "    'Recall@3': round(df_BM_eval_merge['recall@3'].mean(), 2),\n",
    "    'Recall@5': round(df_BM_eval_merge['recall@5'].mean(), 2),\n",
    "    'Recall@7': round(df_BM_eval_merge['recall@7'].mean(), 2),\n",
    "    'MRR@3': round(df_BM_eval_merge['MRR@3'].mean(), 2),\n",
    "    'MRR@5': round(df_BM_eval_merge['MRR@5'].mean(), 2),\n",
    "    'MRR@7': round(df_BM_eval_merge['MRR@7'].mean(), 2),\n",
    "    'HT@3': round(df_BM_eval_merge[df_BM_eval_merge['recall@3'] != 0].shape[0] / len(df_BM_eval_merge), 2),\n",
    "    'HT@5': round(df_BM_eval_merge[df_BM_eval_merge['recall@5'] != 0].shape[0] / len(df_BM_eval_merge), 2),\n",
    "    'HT@7': round(df_BM_eval_merge[df_BM_eval_merge['recall@7'] != 0].shape[0] / len(df_BM_eval_merge), 2)\n",
    "}\n",
    "\n",
    "eval_df.loc[len(eval_df)] = new_data\n",
    "\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c99392",
   "metadata": {},
   "source": [
    "### BM25 with a re-ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "4043512f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BM25_retriever = BM25Retriever.from_defaults(nodes=docs_llama, similarity_top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "de3f355f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BM25_rerank_eval=pd.DataFrame(columns=['_id','query'])\n",
    "df_BM25_rerank_eval[['_id','query']]= df_queries.iloc[:100,:2]\n",
    "df_BM25_rerank_eval_merge= df_BM25_rerank_eval.merge(df_key,left_on='_id',right_on='query-id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "c134232b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BM25_rerank_eval_merge['top5']=df_hybrid_rerank_eval_merge['query'].apply(lambda x:re_ranker(BM25_retriever.retrieve(x),x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2102b930",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BM25_rerank_eval_merge['recall@5'] = df_BM25_rerank_eval_merge.apply(lambda x:calculate_recall(x,k=5), axis=1)\n",
    "df_BM25_rerank_eval_merge['MRR@5'] = df_BM25_rerank_eval_merge.apply(lambda x:calculate_reciprocal_rank(x,k=5), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "803dcd52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Retreival_Technique</th>\n",
       "      <th>Recall@3</th>\n",
       "      <th>Recall@5</th>\n",
       "      <th>Recall@7</th>\n",
       "      <th>MRR@3</th>\n",
       "      <th>MRR@5</th>\n",
       "      <th>MRR@7</th>\n",
       "      <th>HT@3</th>\n",
       "      <th>HT@5</th>\n",
       "      <th>HT@7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text-embedding-ada-002</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>text-embedding-ada-002 + BGE Re_ranker_top5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.85</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BM25 Retreiver</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BM25 Retreiver + BGE Re_ranker_top5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.73</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hybrid reteiver - text-ada+BM25)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hybrid retreiver + BGE Re_ranker_top5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.84</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Retreival_Technique  Recall@3  Recall@5  Recall@7  \\\n",
       "0                       text-embedding-ada-002      0.72      0.82      0.84   \n",
       "1  text-embedding-ada-002 + BGE Re_ranker_top5       NaN      0.82       NaN   \n",
       "2                               BM25 Retreiver      0.63      0.68      0.70   \n",
       "3          BM25 Retreiver + BGE Re_ranker_top5       NaN      0.71       NaN   \n",
       "4             Hybrid reteiver - text-ada+BM25)       NaN      0.77      0.84   \n",
       "5        Hybrid retreiver + BGE Re_ranker_top5       NaN      0.82       NaN   \n",
       "\n",
       "   MRR@3  MRR@5  MRR@7  HT@3  HT@5  HT@7  \n",
       "0   0.66   0.69   0.69  0.73  0.84  0.86  \n",
       "1    NaN   0.67    NaN   NaN  0.85   NaN  \n",
       "2   0.49   0.50   0.50  0.64  0.69  0.71  \n",
       "3    NaN   0.61    NaN   NaN  0.73   NaN  \n",
       "4    NaN    NaN    NaN   NaN  0.77  0.86  \n",
       "5    NaN   0.68    NaN   NaN  0.84   NaN  "
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = {\n",
    "    'Retreival_Technique': 'BM25 Retreiver + BGE Re_ranker_top5',\n",
    "    'Recall@5': round(df_BM25_rerank_eval_merge['recall@5'].mean() , 2),  # Adjust these as needed\n",
    "    'MRR@5': round(df_BM25_rerank_eval_merge['MRR@5'].mean(), 2),\n",
    "    'HT@5': round(df_BM25_rerank_eval_merge[df_BM25_rerank_eval_merge['recall@5'] != 0].shape[0] / len(df_BM25_rerank_eval_merge), 2),\n",
    "}\n",
    "\n",
    "eval_df.loc[3] = new_data\n",
    "\n",
    "eval_df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331c5ec6",
   "metadata": {},
   "source": [
    "### Hybrid custom retreiver ( Vectorstore+BM25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "59f362a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import BaseRetriever\n",
    "                                             \n",
    "class HybridRetriever(BaseRetriever):\n",
    "    def __init__(self, vector_retriever, bm25_retriever):\n",
    "        self.vector_retriever = vector_retriever\n",
    "        self.bm25_retriever = bm25_retriever\n",
    "        super().__init__()\n",
    "\n",
    "    def _retrieve(self, query):\n",
    "        bm25_nodes = self.bm25_retriever.retrieve(query)\n",
    "        vector_nodes = self.vector_retriever.retrieve(query)\n",
    "\n",
    "       # combine the two lists of nodes\n",
    "        all_nodes = []\n",
    "        node_ids = set()\n",
    "        for n in bm25_nodes + vector_nodes:\n",
    "            if n.node.node_id not in node_ids:\n",
    "                all_nodes.append(n)\n",
    "                node_ids.add(n.node.node_id)\n",
    "        return all_nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "1060466c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_retriever = index.as_retriever(similarity_top_k=5)\n",
    "bm25_retriever = BM25Retriever.from_defaults(nodes=docs_llama, similarity_top_k=5)\n",
    "\n",
    "hybrid_retriever = HybridRetriever(vector_retriever, bm25_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "211126ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hybrid2_eval=pd.DataFrame(columns=['_id','query'])\n",
    "df_hybrid2_eval[['_id','query']]= df_queries.iloc[:100,:2]\n",
    "df_hybrid2_eval_merge= df_hybrid2_eval.merge(df_key,left_on='_id',right_on='query-id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "147914f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index(all_nodes):\n",
    "    ci=[]\n",
    "    for c in all_nodes:\n",
    "        ci.append(c.node.metadata['idx'])\n",
    "    return ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "83596d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hybrid2_eval_merge['top5']=df_hybrid2_eval_merge['query'].apply(lambda x:get_index(hybrid_retriever.retrieve(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "0e892f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hybrid2_eval_merge['top10']=df_hybrid2_eval_merge['query'].apply(lambda x:get_index(hybrid_retriever.retrieve(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f25655b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hybrid2_eval_merge['recall@5'] = df_hybrid2_eval_merge.apply(lambda x:calculate_recall(x,k=5), axis=1)\n",
    "df_hybrid2_eval_merge['recall@10'] = df_hybrid2_eval_merge.apply(lambda x:calculate_recall(x,k=10), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "4f25bb5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Retreival_Technique</th>\n",
       "      <th>Recall@3</th>\n",
       "      <th>Recall@5</th>\n",
       "      <th>Recall@7</th>\n",
       "      <th>MRR@3</th>\n",
       "      <th>MRR@5</th>\n",
       "      <th>MRR@7</th>\n",
       "      <th>HT@3</th>\n",
       "      <th>HT@5</th>\n",
       "      <th>HT@7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text-embedding-ada-002</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>text-embedding-ada-002 + BGE Re_ranker_top5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.85</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BM25 Retreiver</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>text-embedding-ada-002 + BGE Re_ranker_top5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.73</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hybrid reteiver - text-ada+BM25)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Retreival_Technique  Recall@3  Recall@5  Recall@7  \\\n",
       "0                       text-embedding-ada-002      0.72      0.82      0.84   \n",
       "1  text-embedding-ada-002 + BGE Re_ranker_top5       NaN      0.82       NaN   \n",
       "2                               BM25 Retreiver      0.63      0.68      0.70   \n",
       "3  text-embedding-ada-002 + BGE Re_ranker_top5       NaN      0.71       NaN   \n",
       "4             Hybrid reteiver - text-ada+BM25)       NaN      0.77      0.84   \n",
       "\n",
       "   MRR@3  MRR@5  MRR@7  HT@3  HT@5  HT@7  \n",
       "0   0.66   0.69   0.69  0.73  0.84  0.86  \n",
       "1    NaN   0.67    NaN   NaN  0.85   NaN  \n",
       "2   0.49   0.50   0.50  0.64  0.69  0.71  \n",
       "3    NaN   0.61    NaN   NaN  0.73   NaN  \n",
       "4    NaN    NaN    NaN   NaN  0.77  0.86  "
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = {\n",
    "    'Retreival_Technique': 'Hybrid reteiver - text-ada+BM25)',\n",
    "    'Recall@5': round(df_hybrid2_eval_merge['recall@5'].mean() , 2),  # Adjust these as needed\n",
    "    'Recall@7': round(df_hybrid2_eval_merge['recall@10'].mean(), 2),\n",
    "    'HT@5': round(df_hybrid2_eval_merge[df_hybrid2_eval_merge['recall@5'] != 0].shape[0] / len(df_hybrid2_eval_merge), 2),\n",
    "    'HT@7': round(df_hybrid2_eval_merge[df_hybrid2_eval_merge['recall@10'] != 0].shape[0] / len(df_hybrid2_eval_merge), 2),\n",
    "}\n",
    "\n",
    "eval_df.loc[len(eval_df)] = new_data\n",
    "\n",
    "eval_df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48893067",
   "metadata": {},
   "source": [
    "### Hybrid custom Retreiver with Re-ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03672250",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.postprocessor import SentenceTransformerRerank\n",
    "reranker = SentenceTransformerRerank(top_n=5, model=\"BAAI/bge-reranker-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "74199271",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hybrid_rerank_eval=pd.DataFrame(columns=['_id','query'])\n",
    "df_hybrid_rerank_eval[['_id','query']]= df_queries.iloc[:100,:2]\n",
    "df_hybrid_rerank_eval_merge= df_hybrid_rerank_eval.merge(df_key,left_on='_id',right_on='query-id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "0e1ce0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import QueryBundle\n",
    "from llama_index.core.schema import NodeWithScore\n",
    "\n",
    "def re_ranker(retrieved_nodes,query):\n",
    "    reranked_nodes = reranker.postprocess_nodes(retrieved_nodes,\n",
    "                                                query_bundle=QueryBundle(query),)\n",
    "    index_id = []\n",
    "    index_id = get_index(reranked_nodes)\n",
    "    return index_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "e0458fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hybrid_rerank_eval_merge['top5']=df_hybrid_rerank_eval_merge['query'].apply(lambda x:re_ranker(hybrid_retriever.retrieve(x),x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3246571",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hybrid_rerank_eval_merge['recall@5'] = df_hybrid_rerank_eval_merge.apply(lambda x:calculate_recall(x,k=5), axis=1)\n",
    "df_hybrid_rerank_eval_merge['MRR@5'] = df_hybrid_rerank_eval_merge.apply(lambda x:calculate_reciprocal_rank(x,k=5), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "b6672065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Retreival_Technique</th>\n",
       "      <th>Recall@3</th>\n",
       "      <th>Recall@5</th>\n",
       "      <th>Recall@7</th>\n",
       "      <th>MRR@3</th>\n",
       "      <th>MRR@5</th>\n",
       "      <th>MRR@7</th>\n",
       "      <th>HT@3</th>\n",
       "      <th>HT@5</th>\n",
       "      <th>HT@7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text-embedding-ada-002</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>text-embedding-ada-002 + BGE Re_ranker_top5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.85</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BM25 Retreiver</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>text-embedding-ada-002 + BGE Re_ranker_top5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.73</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hybrid reteiver - text-ada+BM25)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hybrid retreiver + BGE Re_ranker_top5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.84</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Retreival_Technique  Recall@3  Recall@5  Recall@7  \\\n",
       "0                       text-embedding-ada-002      0.72      0.82      0.84   \n",
       "1  text-embedding-ada-002 + BGE Re_ranker_top5       NaN      0.82       NaN   \n",
       "2                               BM25 Retreiver      0.63      0.68      0.70   \n",
       "3  text-embedding-ada-002 + BGE Re_ranker_top5       NaN      0.71       NaN   \n",
       "4             Hybrid reteiver - text-ada+BM25)       NaN      0.77      0.84   \n",
       "5        Hybrid retreiver + BGE Re_ranker_top5       NaN      0.82       NaN   \n",
       "\n",
       "   MRR@3  MRR@5  MRR@7  HT@3  HT@5  HT@7  \n",
       "0   0.66   0.69   0.69  0.73  0.84  0.86  \n",
       "1    NaN   0.67    NaN   NaN  0.85   NaN  \n",
       "2   0.49   0.50   0.50  0.64  0.69  0.71  \n",
       "3    NaN   0.61    NaN   NaN  0.73   NaN  \n",
       "4    NaN    NaN    NaN   NaN  0.77  0.86  \n",
       "5    NaN   0.68    NaN   NaN  0.84   NaN  "
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = {\n",
    "    'Retreival_Technique': 'Hybrid retreiver + BGE Re_ranker_top5',\n",
    "    'Recall@5': round(df_hybrid_rerank_eval_merge['recall@5'].mean() , 2),  # Adjust these as needed\n",
    "    'MRR@5': round(df_hybrid_rerank_eval_merge['MRR@5'].mean(), 2),\n",
    "    'HT@5': round(df_hybrid_rerank_eval_merge[df_hybrid_rerank_eval_merge['recall@5'] != 0].shape[0] / len(df_hybrid_rerank_eval_merge), 2),\n",
    "}\n",
    "\n",
    "eval_df.loc[len(eval_df)-1] = new_data\n",
    "\n",
    "eval_df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c800c729",
   "metadata": {},
   "source": [
    "### Hybrid Fusion retreiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "08197405",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import RetrieverTool\n",
    "index = load_index_from_storage(storage_context=storage_context)\n",
    "vector_retriever = index.as_retriever(similarity_top_k=3)\n",
    "bm25_retriever = BM25Retriever.from_defaults(nodes=docs_llama, similarity_top_k=3)\n",
    "\n",
    "retriever_tools = [\n",
    "    RetrieverTool.from_defaults(\n",
    "        retriever=vector_retriever,\n",
    "        description=\"Useful in most cases\",\n",
    "    ),\n",
    "    RetrieverTool.from_defaults(\n",
    "        retriever=bm25_retriever,\n",
    "        description=\"Useful if searching about specific information\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "594fc184",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import RouterRetriever\n",
    "\n",
    "retriever = RouterRetriever.from_defaults(\n",
    "    retriever_tools=retriever_tools,\n",
    "    llm=llama_llm,\n",
    "    select_multi=True,\n",
    ")\n",
    "\n",
    "def hybrid_retriever_corpus_index(x):\n",
    "    context = retriever.retrieve(x)\n",
    "    ci=[]\n",
    "    for c in context:\n",
    "        ci.append(c.node.metadata['idx'])\n",
    "    return ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "257e6972",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hybrid_eval=pd.DataFrame(columns=['_id','query'])\n",
    "df_hybrid_eval[['_id','query']]= df_queries.iloc[:100,:2]\n",
    "df_hybrid_eval_merge= df_hybrid_eval.merge(df_key,left_on='_id',right_on='query-id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854ae126",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hybrid_eval_merge['top5']=df_hybrid_eval_merge['query'].apply(lambda x:hybrid_retriever_corpus_index(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0f5221f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.785\n"
     ]
    }
   ],
   "source": [
    "df_hybrid_eval_merge['recall@5'] = df_hybrid_eval_merge.apply(lambda x:calculate_recall(x,k=5), axis=1)\n",
    "print(df_hybrid_eval_merge['recall@5'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e79fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = {\n",
    "    'Retreival_Technique': 'Hybrid retreiver + BGE Re_ranker_top5',\n",
    "    'Recall@5': round(df_hybrid_rerank_eval_merge['recall@5'].mean() , 2),  # Adjust these as needed\n",
    "    'MRR@5': round(df_hybrid_rerank_eval_merge['MRR@5'].mean(), 2),\n",
    "    'HT@5': round(df_hybrid_rerank_eval_merge[df_hybrid_rerank_eval_merge['recall@5'] != 0].shape[0] / len(df_hybrid_rerank_eval_merge), 2),\n",
    "}\n",
    "\n",
    "eval_df.loc[len(eval_df)-1] = new_data\n",
    "\n",
    "eval_df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89e06c9",
   "metadata": {},
   "source": [
    "### Simple Fusion Retreiver (Query rewriting): combine retrieval results from multiple queries and multiple indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "661da88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "index_1 = load_index_from_storage(storage_context=storage_context)\n",
    "index_2 = load_index_from_storage(storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0e2dc289",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import QueryFusionRetriever\n",
    "\n",
    "retriever = QueryFusionRetriever(\n",
    "    [index_1.as_retriever(), index_2.as_retriever()],\n",
    "    similarity_top_k=7,\n",
    "    num_queries=4,  # set this to 1 to disable query generation\n",
    "    use_async=True,\n",
    "    verbose=True,\n",
    "    # query_gen_prompt=\"...\",  # we could override the query generation prompt here\n",
    ")\n",
    "\n",
    "def Fusion_vector_retriever_corpus_index(x):\n",
    "    context = retriever.retrieve(x)\n",
    "    ci=[]\n",
    "    for c in context:\n",
    "        ci.append(c.node.metadata['idx'])\n",
    "    return ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "25da8003",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fusion_eval=pd.DataFrame(columns=['_id','query'])\n",
    "df_fusion_eval[['_id','query']]= df_queries.iloc[:100,:2]\n",
    "df_fusion_eval_merge= df_fusion_eval.merge(df_key,left_on='_id',right_on='query-id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d299b8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply nested async to run in a notebook\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "df_fusion_eval_merge['top3']=df_fusion_eval_merge['query'].apply(lambda x: Fusion_vector_retriever_corpus_index(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cc9cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fusion_eval_merge['top5']=df_fusion_eval_merge['query'].apply(lambda x: Fusion_vector_retriever_corpus_index(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0726fd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fusion_eval_merge['top7']=df_fusion_eval_merge['query'].apply(lambda x: Fusion_vector_retriever_corpus_index(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21a10c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fusion_eval_merge['recall@3'] = df_fusion_eval_merge.apply(lambda x:calculate_recall(x,k=3), axis=1)\n",
    "df_fusion_eval_merge['recall@5'] = df_fusion_eval_merge.apply(lambda x:calculate_recall(x,k=5), axis=1)\n",
    "df_fusion_eval_merge['recall@7'] = df_fusion_eval_merge.apply(lambda x:calculate_recall(x,k=7), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "e89e7804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Retreival_Technique</th>\n",
       "      <th>Recall@3</th>\n",
       "      <th>Recall@5</th>\n",
       "      <th>Recall@7</th>\n",
       "      <th>MRR@3</th>\n",
       "      <th>MRR@5</th>\n",
       "      <th>MRR@7</th>\n",
       "      <th>HT@3</th>\n",
       "      <th>HT@5</th>\n",
       "      <th>HT@7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text-embedding-ada-002</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>text-embedding-ada-002 + BGE Re_ranker_top5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.85</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BM25 Retreiver</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BM25 Retreiver + BGE Re_ranker_top5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.73</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hybrid reteiver - text-ada+BM25)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hybrid retreiver + BGE Re_ranker_top5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.84</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Simple Fusion Retreiver</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Retreival_Technique  Recall@3  Recall@5  Recall@7  \\\n",
       "0                       text-embedding-ada-002      0.72      0.82      0.84   \n",
       "1  text-embedding-ada-002 + BGE Re_ranker_top5       NaN      0.82       NaN   \n",
       "2                               BM25 Retreiver      0.63      0.68      0.70   \n",
       "3          BM25 Retreiver + BGE Re_ranker_top5       NaN      0.71       NaN   \n",
       "4             Hybrid reteiver - text-ada+BM25)       NaN      0.77      0.84   \n",
       "5        Hybrid retreiver + BGE Re_ranker_top5       NaN      0.82       NaN   \n",
       "6                      Simple Fusion Retreiver      0.61      0.81      0.83   \n",
       "\n",
       "   MRR@3  MRR@5  MRR@7  HT@3  HT@5  HT@7  \n",
       "0   0.66   0.69   0.69  0.73  0.84  0.86  \n",
       "1    NaN   0.67    NaN   NaN  0.85   NaN  \n",
       "2   0.49   0.50   0.50  0.64  0.69  0.71  \n",
       "3    NaN   0.61    NaN   NaN  0.73   NaN  \n",
       "4    NaN    NaN    NaN   NaN  0.77  0.86  \n",
       "5    NaN   0.68    NaN   NaN  0.84   NaN  \n",
       "6    NaN    NaN    NaN  0.63  0.82  0.84  "
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = {\n",
    "    'Retreival_Technique': 'Simple Fusion Retreiver',\n",
    "    'Recall@3': round(df_fusion_eval_merge['recall@3'].mean(), 2),\n",
    "    'Recall@5': round(df_fusion_eval_merge['recall@5'].mean(), 2),\n",
    "    'Recall@7': round(df_fusion_eval_merge['recall@7'].mean(), 2),\n",
    "    'HT@3': round(df_fusion_eval_merge[df_fusion_eval_merge['recall@3'] != 0].shape[0] / len(df_fusion_eval_merge), 2),\n",
    "    'HT@5': round(df_fusion_eval_merge[df_fusion_eval_merge['recall@5'] != 0].shape[0] / len(df_fusion_eval_merge), 2),\n",
    "    'HT@7': round(df_fusion_eval_merge[df_fusion_eval_merge['recall@7'] != 0].shape[0] / len(df_fusion_eval_merge), 2)\n",
    "}\n",
    "\n",
    "eval_df.loc[len(eval_df)] = new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "8a839842",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Retreival_Technique</th>\n",
       "      <th>Recall@3</th>\n",
       "      <th>Recall@5</th>\n",
       "      <th>Recall@7</th>\n",
       "      <th>MRR@3</th>\n",
       "      <th>MRR@5</th>\n",
       "      <th>MRR@7</th>\n",
       "      <th>HT@3</th>\n",
       "      <th>HT@5</th>\n",
       "      <th>HT@7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text-embedding-ada-002</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>text-embedding-ada-002 + BGE Re_ranker_top5</td>\n",
       "      <td>-</td>\n",
       "      <td>0.82</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.67</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BM25 Retreiver</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BM25 Retreiver + BGE Re_ranker_top5</td>\n",
       "      <td>-</td>\n",
       "      <td>0.71</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.61</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.73</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hybrid reteiver - text-ada+BM25)</td>\n",
       "      <td>-</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.84</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hybrid retreiver + BGE Re_ranker_top5</td>\n",
       "      <td>-</td>\n",
       "      <td>0.82</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.84</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Simple Fusion Retreiver</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.83</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Retreival_Technique Recall@3  Recall@5 Recall@7  \\\n",
       "0                       text-embedding-ada-002     0.72      0.82     0.84   \n",
       "1  text-embedding-ada-002 + BGE Re_ranker_top5        -      0.82        -   \n",
       "2                               BM25 Retreiver     0.63      0.68      0.7   \n",
       "3          BM25 Retreiver + BGE Re_ranker_top5        -      0.71        -   \n",
       "4             Hybrid reteiver - text-ada+BM25)        -      0.77     0.84   \n",
       "5        Hybrid retreiver + BGE Re_ranker_top5        -      0.82        -   \n",
       "6                      Simple Fusion Retreiver     0.61      0.81     0.83   \n",
       "\n",
       "  MRR@3 MRR@5 MRR@7  HT@3  HT@5  HT@7  \n",
       "0  0.66  0.69  0.69  0.73  0.84  0.86  \n",
       "1     -  0.67     -     -  0.85     -  \n",
       "2  0.49   0.5   0.5  0.64  0.69  0.71  \n",
       "3     -  0.61     -     -  0.73     -  \n",
       "4     -     -     -     -  0.77  0.86  \n",
       "5     -  0.68     -     -  0.84     -  \n",
       "6     -     -     -  0.63  0.82  0.84  "
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After replacing NAN with '-' : \n",
    "eval_df.fillna('_',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018b8c41",
   "metadata": {},
   "source": [
    "## Trying with different chunking strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff6d0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.readers.json import JSONReader\n",
    "reader = JSONReader()\n",
    "documents = reader.load_data(input_file=\"corpus.json\", extra_info={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7edcdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "splitter = SentenceSplitter(\n",
    "    chunk_size=1024,\n",
    "    chunk_overlap=20,\n",
    ")\n",
    "nodes = splitter.get_nodes_from_documents(documents)\n",
    "nodes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7868358d",
   "metadata": {},
   "source": [
    "## Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "258a2937",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "import json\n",
    "docs_langchain=[]\n",
    "        # Load JSON file\n",
    "with open(\"corpus.json\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "    for item in data:\n",
    "        index = item['_id']\n",
    "        title = item['title']\n",
    "        text = item['text']\n",
    "        metadata = dict(idx =index, title= title, extra = item['metadata'])\n",
    "        docs_langchain.append(Document(page_content=text, metadata=metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "46d7201a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', metadata={'idx': '4983', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.', 'extra': {}})"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_langchain[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dcf15ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "vectorstore = FAISS.from_documents(docs_langchain[:1000], embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a3d647b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c1591788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Medullary thymic epithelial cells (mTECs) establish T cell self-tolerance through the expression of autoimmune regulator (Aire) and peripheral tissue-specific self-antigens. However, signals underlying mTEC development remain largely unclear. Here, we demonstrate crucial regulation of mTEC development by receptor activator of NF-kappaB (RANK) and CD40 signals. Whereas only RANK signaling was essential for mTEC development during embryogenesis, in postnatal mice, cooperation between CD40 and RANK signals was required for mTEC development to successfully establish the medullary microenvironment. Ligation of RANK or CD40 on fetal thymic stroma in vitro induced mTEC development in a tumor necrosis factor-associated factor 6 (TRAF6)-, NF-kappaB inducing kinase (NIK)-, and IkappaB kinase beta (IKKbeta)-dependent manner. These results show that developmental-stage-dependent cooperation between RANK and CD40 promotes mTEC development, thereby establishing self-tolerance.', metadata={'idx': '2734421', 'title': 'The tumor necrosis factor family receptors RANK and CD40 cooperatively establish the thymic medullary microenvironment and self-tolerance.', 'extra': {}}),\n",
       " Document(page_content='Aire-expressing medullary thymic epithelial cells (mTECs) play a key role in preventing autoimmunity by expressing tissue-restricted antigens to help purge the emerging T cell receptor repertoire of self-reactive specificities. Here we demonstrate a novel role for a CD4+3 inducer cell population, previously linked to development of organized secondary lymphoid structures and maintenance of T cell memory in the functional regulation of Aire-mediated promiscuous gene expression in the thymus. CD4+3 cells are closely associated with mTECs in adult thymus, and in fetal thymus their appearance is temporally linked with the appearance of Aire+ mTECs. We show that RANKL signals from this cell promote the maturation of RANK-expressing CD80Aire mTEC progenitors into CD80+Aire+ mTECs, and that transplantation of RANK-deficient thymic stroma into immunodeficient hosts induces autoimmunity. Collectively, our data reveal cellular and molecular mechanisms leading to the generation of Aire+ mTECs and highlight a previously unrecognized role for CD4+3RANKL+ inducer cells in intrathymic self-tolerance.', metadata={'idx': '3952288', 'title': 'RANK signals from CD4+3 inducer cells regulate development of Aire-expressing epithelial cells in the thymic medulla', 'extra': {}}),\n",
       " Document(page_content='The thymic medulla provides a specialized microenvironment for the negative selection of T cells, with the presence of autoimmune regulator (Aire)-expressing medullary thymic epithelial cells (mTECs) during the embryonic-neonatal period being both necessary and sufficient to establish long-lasting tolerance. Here we showed that emergence of the first cohorts of Aire(+) mTECs at this key developmental stage, prior to  T cell repertoire selection, was jointly directed by Rankl(+) lymphoid tissue inducer cells and invariant V5(+) dendritic epidermal T cell (DETC) progenitors that are the first thymocytes to express the products of gene rearrangement. In turn, generation of Aire(+) mTECs then fostered Skint-1-dependent, but Aire-independent, DETC progenitor maturation and the emergence of an invariant DETC repertoire. Hence, our data attributed a functional importance to the temporal development of V5(+)  T cells during thymus medulla formation for  T cell tolerance induction and demonstrated a Rank-mediated reciprocal link between DETC and Aire(+) mTEC maturation.', metadata={'idx': '301838', 'title': 'Rank Signaling Links the Development of Invariant  T Cell Progenitors and Aire+ Medullary Epithelium', 'extra': {}}),\n",
       " Document(page_content='Autoimmune polyendocrinopathy syndrome type 1 is a recessive Mendelian disorder resulting from mutations in a novel gene, AIRE, and is characterized by a spectrum of organ-specific autoimmune diseases. It is not known what tolerance mechanisms are defective as a result of AIRE mutation. By tracing the fate of autoreactive CD4+ T cells with high affinity for a pancreatic antigen in transgenic mice with an Aire mutation, we show here that Aire deficiency causes almost complete failure to delete the organ-specific cells in the thymus. These results indicate that autoimmune polyendocrinopathy syndrome 1 is caused by failure of a specialized mechanism for deleting forbidden T cell clones, establishing a central role for this tolerance mechanism.', metadata={'idx': '4561402', 'title': 'Aire regulates negative selection of organ-specific T cells', 'extra': {}})]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = retriever.invoke(\"RANK-RANKL pathway signalling has no known association with development of Aire-expressing medullary thymic epithelial cells.\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c1ccc6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vectorstore.similarity_search_with_score(\"RANK-RANKL pathway signalling has no known association with development of Aire-expressing medullary thymic epithelial cells.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
